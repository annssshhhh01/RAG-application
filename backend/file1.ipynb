{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec2e0ac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ansh\\OneDrive\\Desktop\\LANGCHAIN_INTERIM_PROJECT\\main\\rag_engine.py:39: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the `langchain-huggingface package and should be used instead. To use it run `pip install -U `langchain-huggingface` and import as `from `langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings=HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
      "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e462baf8f96a425c81a34f62a90c6cf4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/103 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BertModel LOAD REPORT from: sentence-transformers/all-MiniLM-L6-v2\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "Notes:\n",
      "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I don't know\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "from rag_engine import document_loader, ingest_document, llm_call\n",
    "\n",
    "documents = document_loader(\"sample.pdf\")\n",
    "vector_store = ingest_document(documents)\n",
    "\n",
    "result = llm_call(vector_store, \"What is this document about?\")\n",
    "print(result[\"answer\"])\n",
    "print(result[\"sources\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "ef82bcbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'source': 'langchain_notes', 'doc_id': 1, 'chunk_id': 0}, page_content='LangChain is a framework for building applications powered by large language models.'), Document(metadata={'source': 'langchain_notes', 'doc_id': 1}, page_content='It helps developers connect language models with external data sources.'), Document(metadata={'source': 'faiss_notes', 'doc_id': 2}, page_content='FAISS is a library for efficient similarity search over dense vector embeddings.'), Document(metadata={'source': 'faiss_notes', 'doc_id': 2}, page_content='It is commonly used as a vector database in RAG systems.'), Document(metadata={'source': 'rag_notes', 'doc_id': 3}, page_content='Retrieval-Augmented Generation (RAG) combines retrieval with generation to reduce hallucinations.'), Document(metadata={'source': 'rag_notes', 'doc_id': 3}, page_content='It ensures that language models answer based on external evidence.')]\n",
      "[Document(metadata={'source': 'langchain_notes', 'doc_id': 1, 'chunk_id': 0}, page_content='LangChain is a framework for building applications powered by large language models.'), Document(metadata={'source': 'langchain_notes', 'doc_id': 1, 'chunk_id': 1}, page_content='It helps developers connect language models with external data sources.'), Document(metadata={'source': 'faiss_notes', 'doc_id': 2}, page_content='FAISS is a library for efficient similarity search over dense vector embeddings.'), Document(metadata={'source': 'faiss_notes', 'doc_id': 2}, page_content='It is commonly used as a vector database in RAG systems.'), Document(metadata={'source': 'rag_notes', 'doc_id': 3}, page_content='Retrieval-Augmented Generation (RAG) combines retrieval with generation to reduce hallucinations.'), Document(metadata={'source': 'rag_notes', 'doc_id': 3}, page_content='It ensures that language models answer based on external evidence.')]\n",
      "[Document(metadata={'source': 'langchain_notes', 'doc_id': 1, 'chunk_id': 0}, page_content='LangChain is a framework for building applications powered by large language models.'), Document(metadata={'source': 'langchain_notes', 'doc_id': 1, 'chunk_id': 1}, page_content='It helps developers connect language models with external data sources.'), Document(metadata={'source': 'faiss_notes', 'doc_id': 2, 'chunk_id': 2}, page_content='FAISS is a library for efficient similarity search over dense vector embeddings.'), Document(metadata={'source': 'faiss_notes', 'doc_id': 2}, page_content='It is commonly used as a vector database in RAG systems.'), Document(metadata={'source': 'rag_notes', 'doc_id': 3}, page_content='Retrieval-Augmented Generation (RAG) combines retrieval with generation to reduce hallucinations.'), Document(metadata={'source': 'rag_notes', 'doc_id': 3}, page_content='It ensures that language models answer based on external evidence.')]\n",
      "[Document(metadata={'source': 'langchain_notes', 'doc_id': 1, 'chunk_id': 0}, page_content='LangChain is a framework for building applications powered by large language models.'), Document(metadata={'source': 'langchain_notes', 'doc_id': 1, 'chunk_id': 1}, page_content='It helps developers connect language models with external data sources.'), Document(metadata={'source': 'faiss_notes', 'doc_id': 2, 'chunk_id': 2}, page_content='FAISS is a library for efficient similarity search over dense vector embeddings.'), Document(metadata={'source': 'faiss_notes', 'doc_id': 2, 'chunk_id': 3}, page_content='It is commonly used as a vector database in RAG systems.'), Document(metadata={'source': 'rag_notes', 'doc_id': 3}, page_content='Retrieval-Augmented Generation (RAG) combines retrieval with generation to reduce hallucinations.'), Document(metadata={'source': 'rag_notes', 'doc_id': 3}, page_content='It ensures that language models answer based on external evidence.')]\n",
      "[Document(metadata={'source': 'langchain_notes', 'doc_id': 1, 'chunk_id': 0}, page_content='LangChain is a framework for building applications powered by large language models.'), Document(metadata={'source': 'langchain_notes', 'doc_id': 1, 'chunk_id': 1}, page_content='It helps developers connect language models with external data sources.'), Document(metadata={'source': 'faiss_notes', 'doc_id': 2, 'chunk_id': 2}, page_content='FAISS is a library for efficient similarity search over dense vector embeddings.'), Document(metadata={'source': 'faiss_notes', 'doc_id': 2, 'chunk_id': 3}, page_content='It is commonly used as a vector database in RAG systems.'), Document(metadata={'source': 'rag_notes', 'doc_id': 3, 'chunk_id': 4}, page_content='Retrieval-Augmented Generation (RAG) combines retrieval with generation to reduce hallucinations.'), Document(metadata={'source': 'rag_notes', 'doc_id': 3}, page_content='It ensures that language models answer based on external evidence.')]\n",
      "[Document(metadata={'source': 'langchain_notes', 'doc_id': 1, 'chunk_id': 0}, page_content='LangChain is a framework for building applications powered by large language models.'), Document(metadata={'source': 'langchain_notes', 'doc_id': 1, 'chunk_id': 1}, page_content='It helps developers connect language models with external data sources.'), Document(metadata={'source': 'faiss_notes', 'doc_id': 2, 'chunk_id': 2}, page_content='FAISS is a library for efficient similarity search over dense vector embeddings.'), Document(metadata={'source': 'faiss_notes', 'doc_id': 2, 'chunk_id': 3}, page_content='It is commonly used as a vector database in RAG systems.'), Document(metadata={'source': 'rag_notes', 'doc_id': 3, 'chunk_id': 4}, page_content='Retrieval-Augmented Generation (RAG) combines retrieval with generation to reduce hallucinations.'), Document(metadata={'source': 'rag_notes', 'doc_id': 3, 'chunk_id': 5}, page_content='It ensures that language models answer based on external evidence.')]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac84a51894da492085cd0944231ed116",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/103 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BertModel LOAD REPORT from: sentence-transformers/all-MiniLM-L6-v2\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "Notes:\n",
      "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " I don't know-insufficent knowledge,\n",
      "[{'type': 'text', 'text': 'Retrieval-Augmented Generation (RAG) combines retrieval with generation to reduce hallucinations.', 'extras': {'signature': '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'}}]\n",
      "[{'source': 'faiss_notes', 'chunk_id': 3, 'score': np.float32(0.901234)}, {'source': 'rag_notes', 'chunk_id': 4, 'score': np.float32(1.2693634)}]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "texts=[doc1,doc2,doc3]\n",
    "metadatas = [\n",
    "    {\"source\": \"langchain_notes\", \"doc_id\": 1},\n",
    "    {\"source\": \"faiss_notes\", \"doc_id\": 2},\n",
    "    {\"source\": \"rag_notes\", \"doc_id\": 3}\n",
    "]\n",
    "vector_store=ingest_document(texts,metadatas)\n",
    "result=llm_call(vector_store,\"what is RAG?\")\n",
    "print(result[\"answer\"])\n",
    "print(result[\"sources\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603d631b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "runnablemain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
